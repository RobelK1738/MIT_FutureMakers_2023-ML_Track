# Classification Loss Functions

## Topics covered in today's module
* Kullback Leibler Divergence Loss
* Binary Cross-Entropy
* Categorical Cross-Entropy
* Sparse Categorical Cross-Entropy

## Main takeaways from doing today's assignment
* Keras implementation of AdaGrad optimizer

## Challenging, interesting, or exciting aspects of today's assignment
* SGD Vs BGD optimization algorithms

## Additional resources used 
* https://keras.io/api/optimizers/
* ChatGPT
